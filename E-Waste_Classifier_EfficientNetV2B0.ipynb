{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25a0118a",
   "metadata": {},
   "source": [
    "# 📁 E-Waste Image Classification using EfficientNetV2B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2c045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from keras.layers import Input, GlobalAveragePooling2D, Dropout, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.applications.efficientnet_v2 import preprocess_input\n",
    "from keras.applications import EfficientNetV2B0\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8019fc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2400 files belonging to 10 classes.\n",
      "Found 300 files belonging to 10 classes.\n",
      "Found 300 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATASET_PATH = r\"D:\\E-waste generation classification\"\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    os.path.join(DATASET_PATH, \"train\"),\n",
    "    image_size=(128, 128),\n",
    "    batch_size=100\n",
    ")\n",
    "\n",
    "val_dataset = image_dataset_from_directory(\n",
    "    os.path.join(DATASET_PATH, \"validation\"),\n",
    "    image_size=(128, 128),\n",
    "    batch_size=100\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    os.path.join(DATASET_PATH, \"test\"),\n",
    "    image_size=(128, 128),\n",
    "    batch_size=100\n",
    ")\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.map(lambda x, y: (preprocess_input(x), y)).cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = val_dataset.map(lambda x, y: (preprocess_input(x), y)).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.map(lambda x, y: (preprocess_input(x), y)).cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d4e2162",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model = EfficientNetV2B0(include_top=False, input_tensor=Input(shape=(128, 128, 3)), weights=\"imagenet\")\n",
    "base_model.trainable = True\n",
    "\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.2)(x)\n",
    "output = Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96a79138",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4998645d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 2s/step - accuracy: 0.1908 - loss: 2.2652 - val_accuracy: 0.6233 - val_loss: 1.5630\n",
      "Epoch 2/15\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 0.6638 - loss: 1.3980 - val_accuracy: 0.8267 - val_loss: 0.9605\n",
      "Epoch 3/15\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 0.8815 - loss: 0.7697 - val_accuracy: 0.8800 - val_loss: 0.6045\n",
      "Epoch 4/15\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 0.9371 - loss: 0.4636 - val_accuracy: 0.9100 - val_loss: 0.4164\n",
      "Epoch 5/15\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 0.9471 - loss: 0.2872 - val_accuracy: 0.9200 - val_loss: 0.3167\n",
      "Epoch 6/15\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 0.9768 - loss: 0.1792 - val_accuracy: 0.9367 - val_loss: 0.2568\n",
      "Epoch 7/15\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 0.9835 - loss: 0.1273 - val_accuracy: 0.9533 - val_loss: 0.2221\n",
      "Epoch 8/15\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 0.9900 - loss: 0.0953 - val_accuracy: 0.9567 - val_loss: 0.1929\n",
      "Epoch 9/15\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 0.9967 - loss: 0.0625 - val_accuracy: 0.9600 - val_loss: 0.1791\n",
      "Epoch 10/15\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 0.9965 - loss: 0.0477 - val_accuracy: 0.9633 - val_loss: 0.1675\n",
      "Epoch 11/15\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 0.9984 - loss: 0.0360 - val_accuracy: 0.9533 - val_loss: 0.1623\n",
      "Epoch 12/15\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 0.9992 - loss: 0.0266 - val_accuracy: 0.9600 - val_loss: 0.1518\n",
      "Epoch 13/15\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0242 - val_accuracy: 0.9600 - val_loss: 0.1424\n",
      "Epoch 14/15\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 0.9972 - loss: 0.0198 - val_accuracy: 0.9633 - val_loss: 0.1423\n",
      "Epoch 15/15\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.9633 - val_loss: 0.1379\n"
     ]
    }
   ],
   "source": [
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a79568c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 572ms/step - accuracy: 0.9688 - loss: 0.1139\n",
      "Test Loss: 0.1446\n",
      "Test Accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4663f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the trained model\n",
    "model.save(\"e_waste_classifier_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdf5dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "Could not create share link. Missing file: C:\\Users\\pranj\\.cache\\huggingface\\gradio\\frpc\\frpc_windows_amd64_v0.3. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_windows_amd64.exe\n",
      "2. Rename the downloaded file to: frpc_windows_amd64_v0.3\n",
      "3. Move the file to this location: C:\\Users\\pranj\\.cache\\huggingface\\gradio\\frpc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract class_names from the original dataset object before mapping\n",
    "class_names = train_dataset.class_names if hasattr(train_dataset, 'class_names') else [\n",
    "    'Battery', 'Keyboard', 'Microwave', 'Mobile', 'Mouse', 'PCB', 'Player', 'Printer', 'TV', 'Washing Machine'\n",
    "]\n",
    "\n",
    "def classify_image(img):\n",
    "    img = tf.image.resize(img, [128, 128])\n",
    "    img = preprocess_input(img)\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "    predictions = model.predict(img)\n",
    "    label = class_names[np.argmax(predictions)]\n",
    "    confidence = np.max(predictions)\n",
    "    return {label: float(confidence)}\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=classify_image,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=gr.Label(num_top_classes=3),\n",
    "    title=\"E-Waste Image Classifier\",\n",
    "    description=\"Upload an e-waste image to classify into 1 of 10 categories.\"\n",
    ")\n",
    "\n",
    "interface.launch(share=True)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
